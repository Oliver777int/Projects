{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Code generates a 2D moving particle in a box. The movement is recorded for a number of frames and the goal is for a transformer encoder to predict the movement of the particle by predicting the next frame. To achieve this, the particle frames are first compressed from a 2D array into a 1D array representation of size = n. This is done by creating an autoencoder where n is the bottleneck size containing the neccesary information to recreate the particle. After that the compressed representation (Encoded dataset) is used to train a transformer encoder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset can be generated with the code below, however after running once, they can be loaded from numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeptrack as dt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "sequence_length = 50  # Number of frames per sequence\n",
    "MIN_SIZE = 0.5e-6\n",
    "MAX_SIZE = 1.5e-6\n",
    "MAX_VEL = 10  # Maximum velocity. Higher = Trickier.\n",
    "MAX_PARTICLES = 3  # Max number of particles in each sequence. Higher = Trickier.\n",
    "\n",
    "# Defining properties of the particles\n",
    "particle = dt.Sphere(\n",
    "    intensity=lambda: 10 + 10 * np.random.rand(),\n",
    "    radius=lambda: MIN_SIZE + np.random.rand() * (MAX_SIZE - MIN_SIZE),\n",
    "    position=lambda: IMAGE_SIZE * np.random.rand(2),\n",
    "    vel=lambda: MAX_VEL * np.random.rand(2),\n",
    "    position_unit=\"pixel\",\n",
    ")\n",
    "\n",
    "# Defining an update rule for the particle position\n",
    "def get_position(previous_value, vel):\n",
    "\n",
    "    newv = previous_value + vel\n",
    "    for i in range(2):\n",
    "        if newv[i] > 63:\n",
    "            newv[i] = 63 - np.abs(newv[i] - 63)\n",
    "            vel[i] = -vel[i]\n",
    "        elif newv[i] < 0:\n",
    "            newv[i] = np.abs(newv[i])\n",
    "            vel[i] = -vel[i]\n",
    "    return newv\n",
    "\n",
    "\n",
    "particle = dt.Sequential(particle, position=get_position)\n",
    "\n",
    "# Defining properties of the microscope\n",
    "optics = dt.Fluorescence(\n",
    "    NA=1,\n",
    "    output_region=(0, 0, IMAGE_SIZE, IMAGE_SIZE),\n",
    "    magnification=10,\n",
    "    resolution=(1e-6, 1e-6, 1e-6),\n",
    "    wavelength=633e-9,\n",
    ")\n",
    "\n",
    "# Combining everything into a dataset.\n",
    "# Note that the sequences are flipped in different directions, so that each unique sequence defines\n",
    "# in fact 8 sequences flipped in different directions, to speed up data generation\n",
    "sequential_images = dt.Sequence(\n",
    "    optics(particle ** (lambda: 1 + np.random.randint(MAX_PARTICLES))),\n",
    "    sequence_length=sequence_length,\n",
    ")\n",
    "dataset = sequential_images >> dt.FlipUD() >> dt.FlipDiagonal() >> dt.FlipLR()\n",
    "\n",
    "training_data2 = [dataset.update()() for i in tqdm(range(1000))]\n",
    "validation_data = [dataset.update()() for i in tqdm(range(100))]\n",
    "long_sequence_data = [dataset.update()() for i in tqdm(range(100))]\n",
    "\n",
    "np.save('long.npy', np.array(long_sequence_data))\n",
    "np.save('train2.npy', np.array(training_data2))\n",
    "np.save('val.npy', np.array(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset (Requires that the above code has been run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "training_data = np.load('train.npy')\n",
    "extra_training_data = np.load('train2.npy')\n",
    "training_data = np.concatenate([training_data, extra_training_data[:,0:10,:,:,:]], axis=0)\n",
    "validation_data = np.load('val.npy')\n",
    "long_data = np.load('long.npy')\n",
    "sequence_length = training_data.shape[1]\n",
    "samples = training_data.shape[0]\n",
    "longest_data = np.load('longest.npy')\n",
    "\n",
    "# Normalization\n",
    "max_value = np.amax(training_data)\n",
    "training_data = training_data / max_value\n",
    "validation_data = validation_data / max_value\n",
    "long_data = long_data / max_value\n",
    "longest_data = longest_data / max_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the structure of the Autoencoder followed by a cell for training, Evaluating, Saving and Loading. After training and saving once, the model can be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure\n",
    "Conv2D = keras.layers.Conv2D\n",
    "MaxPool2D = keras.layers.MaxPooling2D\n",
    "Dense = keras.layers.Dense\n",
    "Flatten = keras.layers.Flatten\n",
    "Reshape=keras.layers.Reshape\n",
    "Upsample2D=keras.layers.UpSampling2D\n",
    "\n",
    "encoder = keras.models.Sequential()\n",
    "encoder.add(Conv2D(8,(3,3), activation=\"relu\", padding=\"same\", input_shape=(64,64,1)))\n",
    "encoder.add(MaxPool2D(pool_size=(2,2)))\n",
    "encoder.add(Conv2D(16,(3,3), activation=\"relu\", padding=\"same\"))\n",
    "encoder.add(MaxPool2D(pool_size=(2,2)))\n",
    "encoder.add(Conv2D(32,(3,3), activation=\"relu\", padding=\"same\"))\n",
    "encoder.add(Flatten())\n",
    "encoder.add(Dense(32))\n",
    "encoder.add(Dense(16))\n",
    "encoder.add(Dense(5))\n",
    "\n",
    "decoder = keras.models.Sequential()\n",
    "decoder.add(Dense(16))\n",
    "decoder.add(Dense(32))\n",
    "decoder.add(Dense(16*16*32))\n",
    "decoder.add(Reshape((16,16,32)))\n",
    "decoder.add(Conv2D(32,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "decoder.add(Upsample2D((2,2)))\n",
    "decoder.add(Conv2D(16,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "decoder.add(Upsample2D((2,2)))\n",
    "decoder.add(Conv2D(8,(3,3),activation=\"relu\",padding=\"same\"))\n",
    "decoder.add(Conv2D(1,(3,3),padding=\"same\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the autoencoder\n",
    "input = keras.layers.Input((64,64,1))\n",
    "autoencoder=keras.models.Model(inputs=input,outputs=decoder(encoder(input)))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "autoencoder.compile(optimizer=optimizer, loss=\"mae\")\n",
    "autoencoder.fit(x=np.array(training_data).reshape(sequence_length*samples,64,64,1), y=np.array(training_data).reshape(sequence_length*samples,64,64,1),epochs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the autoencoder\n",
    "score = autoencoder.evaluate(x=np.array(validation_data).reshape(1000,64,64,1), y=np.array(validation_data).reshape(1000,64,64,1))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "autoencoder.save('saved_models/autoencoder')\n",
    "encoder.save('saved_models/encoder')\n",
    "decoder.save('saved_models/decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "encoder = keras.models.load_model(\"saved_models/encoder\")\n",
    "decoder = keras.models.load_model(\"saved_models/decoder\")\n",
    "autoencoder = keras.models.load_model(\"saved_models/autoencoder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is used to plot the output of the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a = tf.reshape(autoencoder(np.array(validation_data).reshape(-1, 64, 64, 1)), [-1, 10, 64, 64, 1])\n",
    "print(np.shape(a), np.shape(validation_data))\n",
    "for i in range(5):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.axis('off')\n",
    "    if i == 2:\n",
    "        plt.title('Real images')\n",
    "    plt.imshow(np.array(validation_data)[40,i+5,:,:])\n",
    "    plt.subplot(2,5,i+6)\n",
    "    plt.axis('off')\n",
    "    if i == 2:\n",
    "        plt.title(r'Decoded images from autoencoder')\n",
    "    plt.imshow(a[40,i+5,:,:])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell passes the training set and the validation set into the encoder. The encoded dataset consists of the first 9 frames and the 10th frame is used as target/label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 # Bottleneck size\n",
    "# Training set\n",
    "encoded_training_set = encoder(training_data.reshape(-1, 64, 64, 1))\n",
    "encoded_training_set = tf.reshape(encoded_training_set, [samples, sequence_length, n])\n",
    "encoded_training_labels = tf.reshape(encoded_training_set[:,9,:], [samples,1,n])\n",
    "encoded_training_set = encoded_training_set[:,:9,:]\n",
    "\n",
    "# Validation set\n",
    "encoded_validation_set = encoder(validation_data.reshape(-1, 64, 64, 1))\n",
    "encoded_validation_set = tf.reshape(encoded_validation_set, [100, 10, n])\n",
    "encoded_validation_labels = tf.reshape(encoded_validation_set[:,9,:], [100,1,n])\n",
    "encoded_validation_set = encoded_validation_set[:,:9,:]\n",
    "\n",
    "# Sequences of length 20 and 50 (used to evaluate several predictions into the future)\n",
    "encoded_long_labels = encoder(long_data.reshape(-1, 64, 64, 1))\n",
    "encoded_long_labels = tf.reshape(encoded_long_labels, [100, 20, n])\n",
    "\n",
    "print('Shape of training set after being encoded: ', np.shape(encoded_training_set))\n",
    "print('Shape of training labels after being encoded: ', np.shape(encoded_training_labels))\n",
    "print('Shape of validation set after being encoded: ' ,np.shape(encoded_validation_set))\n",
    "print('Shape of validation labels after being encoded: ', np.shape(encoded_validation_labels))\n",
    "\n",
    "np.save('enc_train_set.npy', encoded_training_set)\n",
    "np.save('enc_train_lab.npy', encoded_training_labels)\n",
    "np.save('enc_val_set.npy', encoded_validation_set)\n",
    "np.save('enc_val_lab.npy', encoded_validation_labels)\n",
    "np.save('enc_long_lab.npy', encoded_long_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encoded dataset.\n",
    "encoded_training_set = np.load('enc_train_set.npy')\n",
    "encoded_training_labels = np.load('enc_train_lab.npy')\n",
    "encoded_validation_set = np.load('enc_val_set.npy')\n",
    "encoded_validation_labels = np.load('enc_val_lab.npy')\n",
    "encoded_long_labels = np.load('enc_long_lab.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes used in the Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras.layers import Dense\n",
    "\n",
    "class Time2Vector(Layer):\n",
    "    def __init__(self, seq_len, **kwargs):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.weights_linear = self.add_weight(name='weight_linear',shape=(int(self.seq_len),),initializer='uniform',trainable=True)\n",
    "        self.bias_linear = self.add_weight(name='bias_linear',shape=(int(self.seq_len),),initializer='uniform',trainable=True)\n",
    "        self.weights_periodic = self.add_weight(name='weight_periodic',shape=(int(self.seq_len),),initializer='uniform',trainable=True)\n",
    "        self.bias_periodic = self.add_weight(name='bias_periodic',shape=(int(self.seq_len),),initializer='uniform',trainable=True)\n",
    "        self.weights_periodic2 = self.add_weight(name='weight_periodic',shape=(int(self.seq_len),),initializer='uniform',trainable=True)\n",
    "        self.bias_periodic2 = self.add_weight(name='bias_periodic',shape=(int(self.seq_len),),initializer='uniform',trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        x1 = tf.math.reduce_mean(x[:,:,:], axis=-1)\n",
    "        time_linear = self.weights_linear * x1 + self.bias_linear\n",
    "        time_linear = tf.expand_dims(time_linear, axis=-1)\n",
    "        time_periodic = tf.math.sin(tf.multiply(x1, self.weights_periodic) + self.bias_periodic)\n",
    "        time_periodic = tf.expand_dims(time_periodic, axis=-1)\n",
    "        time_periodic2 = tf.math.sin(tf.multiply(x1, self.weights_periodic2) + self.bias_periodic2)\n",
    "        time_periodic2 = tf.expand_dims(time_periodic2, axis=-1)\n",
    "        time_embedding = tf.concat([time_linear, time_periodic, time_periodic2], axis=-1)\n",
    "        return tf.concat([x, time_embedding], axis=-1)     # x = (batch, sequence, input + time embedding)\n",
    "\n",
    "\n",
    "class SingleAttention(Layer):\n",
    "    def __init__(self, d_k, d_v, **kwargs):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "        self.key = Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "        self.value = Dense(self.d_v, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        q = self.query(inputs[0])\n",
    "        k = self.key(inputs[1])\n",
    "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "        attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
    "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "        v = self.value(inputs[2])\n",
    "        attn_out = tf.matmul(attn_weights, v)\n",
    "        return attn_out\n",
    "    \n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, seq_len, dk, dv, filter_dim, ff_dim, **kwargs):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.dk = dk\n",
    "        self.dv = dv\n",
    "        self.filter_dim = filter_dim\n",
    "        self.ff_dim = ff_dim\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.head1 = SingleAttention(self.dk, self.dv)\n",
    "        self.head2 = SingleAttention(self.dk, self.dv)\n",
    "        self.head3 = SingleAttention(self.dk, self.dv)\n",
    "        self.head4 = SingleAttention(self.dk, self.dv)\n",
    "        self.head5 = SingleAttention(self.dk, self.dv)\n",
    "        self.head6 = SingleAttention(self.dk, self.dv)\n",
    "        self.norm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = keras.layers.Dropout(0.1)\n",
    "        self.attention_dense = Dense(self.filter_dim, input_shape=(None, self.seq_len, self.dv*6), kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "        self.ff_dense = keras.layers.Dense(self.ff_dim, activation='relu')\n",
    "        self.filter_dense = keras.layers.Dense(self.filter_dim)\n",
    "        #self.mha = keras.layers.MultiHeadAttention(num_heads=10, key_dim=7)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Multihead attention with 3 heads.\n",
    "        attn_head1 = self.dropout(self.head1([inputs, inputs, inputs]))\n",
    "        attn_head2 = self.dropout(self.head2([inputs, inputs, inputs]))\n",
    "        attn_head3 = self.dropout(self.head3([inputs, inputs, inputs]))\n",
    "        attn_head4 = self.dropout(self.head4([inputs, inputs, inputs]))\n",
    "        attn_head5 = self.dropout(self.head5([inputs, inputs, inputs]))\n",
    "        attn_head6 = self.dropout(self.head6([inputs, inputs, inputs]))\n",
    "        attn_concat = tf.concat([attn_head1, attn_head2, attn_head3, attn_head4, attn_head5, attn_head6], axis=-1)\n",
    "        multi_attn = self.attention_dense(attn_concat)\n",
    "        #multi_attn = self.mha(query=inputs, key=inputs, value=inputs)\n",
    "        \n",
    "        # FFNN with residual connections \n",
    "        x1 = self.norm1(inputs + multi_attn)\n",
    "        x2 = self.ff_dense(x1)\n",
    "        x2 = self.filter_dense(x2)\n",
    "        x2 = self.dropout(x2)\n",
    "        output = self.norm2(x1 + x2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Transformer encoder and an LSTM model for comparison. seq_len is the number of frames used as input, dk and dv are parameter in the self-attention, ff_dim is the feedforward layer size and filter_dim the output dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 # Bottleneck size\n",
    "\n",
    "# Transformer Encoder\n",
    "transformerEncoder = keras.models.Sequential()\n",
    "transformerEncoder.add(Time2Vector(9))\n",
    "transformerEncoder.add(TransformerBlock(seq_len=9, dk=7, dv=7, filter_dim=7, ff_dim=32))\n",
    "transformerEncoder.add(TransformerBlock(seq_len=9, dk=7, dv=7, filter_dim=7, ff_dim=32))\n",
    "transformerEncoder.add(TransformerBlock(seq_len=9, dk=7, dv=7, filter_dim=7, ff_dim=32))\n",
    "transformerEncoder.add(TransformerBlock(seq_len=9, dk=7, dv=7, filter_dim=7, ff_dim=32))\n",
    "transformerEncoder.add(keras.layers.AveragePooling1D(pool_size=9, input_shape=(9, 7)))\n",
    "transformerEncoder.add(keras.layers.Dense(units=n, activation='linear'))\n",
    "\n",
    "# The LSTM model\n",
    "LSTM_model = keras.models.Sequential()\n",
    "LSTM_model.add(Time2Vector(9))\n",
    "LSTM_model.add(tf.keras.layers.LSTM(32, dropout=0.1, input_shape=(9,6), return_sequences=True))\n",
    "LSTM_model.add(tf.keras.layers.LSTM(32, dropout=0.1, return_sequences=True))\n",
    "LSTM_model.add(tf.keras.layers.LSTM(32, dropout=0.1))\n",
    "LSTM_model.add(keras.layers.Dense(units=n, activation='linear'))\n",
    "LSTM_model.add(keras.layers.Reshape(target_shape=(1, n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "input = keras.layers.Input(shape=[9, n])\n",
    "transformerModel=keras.models.Model(inputs=input,outputs=transformerEncoder(input))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "transformerModel.compile(optimizer=optimizer, loss=\"mse\")\n",
    "transformerModel.fit(x=np.array(encoded_training_set), y=np.array(encoded_training_labels), epochs=200)\n",
    "\n",
    "# Evaluation\n",
    "score = transformerModel.evaluate(x=np.array(encoded_validation_set), y=np.array(encoded_validation_labels))\n",
    "print(score)\n",
    "\n",
    "# Saving\n",
    "#transformerModel.save('saved_models/transformer')\n",
    "#transformerModel = keras.models.load_model(\"saved_models/transformer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is used to generate plots of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_prediction(sequence, seq_len):\n",
    "    encoded_sequence = encoder(np.array(tf.reshape(sequence, [-1, 64, 64, 1])))\n",
    "    encoded_sequence = tf.reshape(encoded_sequence, [-1, seq_len, n])\n",
    "    encoded_sequence = encoded_sequence[:,-9:,:]\n",
    "    predicted_datapoint = transformerModel(encoded_sequence)\n",
    "    output = tf.expand_dims(decoder(predicted_datapoint[:,0,:]), axis=1)\n",
    "    return output\n",
    "\n",
    "def make_prediction(sequence, n_predictions):\n",
    "    for ii in range(n_predictions):\n",
    "        new_datapoint = single_prediction(sequence, np.shape(sequence)[1])\n",
    "        sequence = tf.concat([sequence, new_datapoint], axis=1)\n",
    "    return sequence\n",
    "\n",
    "def future_prediction_power(input_sequence, n_predictions):\n",
    "    sequence = make_prediction(input_sequence, n_predictions)\n",
    "    encoded_sequence = encoder(tf.reshape(sequence, [-1, 64, 64, 1]))\n",
    "    encoded_sequence = tf.reshape(encoded_sequence, [100, 9+n_predictions, n])\n",
    "    print(np.shape(encoded_long_labels))\n",
    "    print(np.shape(encoded_sequence))\n",
    "    print(np.shape(encoded_sequence[:,0:0+9,:]))\n",
    "    scores = []\n",
    "    for i in range(n_predictions+1):\n",
    "        score = transformerModel.evaluate(x=np.array(encoded_sequence[:,i:i+9,:]), y=np.array(encoded_long_labels[:,i+9,:]).reshape(100,1,n))\n",
    "        scores.append(score)\n",
    "    plt.plot(scores)\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Number of frames predicted')\n",
    "    plt.title('Future predictive power')\n",
    "        \n",
    "\n",
    "input_sequence = long_data[:,0:9,:,:,:]\n",
    "\n",
    "future_prediction_power(input_sequence, 10)\n",
    "\n",
    "if False:\n",
    "    idx = 3\n",
    "    input_sequence = make_prediction(input_sequence, 9*3)\n",
    "    fig, axs = plt.subplots(2,9,figsize=(16,9))\n",
    "    for i in range(9):\n",
    "        axs[1, i].imshow(input_sequence[idx,9+i,:,:,0])\n",
    "        axs[1, i].set_title(f'Pred. frame {i+1}')\n",
    "        axs[0, i].imshow(longest_data[idx,9+i,:,:,0])\n",
    "        axs[0, i].set_title(f'Real frame {i+1}')\n",
    "\n",
    "    fig, axs = plt.subplots(2,9,figsize=(16,9))\n",
    "    for i in range(9):\n",
    "        axs[1, i].imshow(input_sequence[idx,18+i,:,:,0])\n",
    "        axs[1, i].set_title(f'Pred. frame {i+10}')\n",
    "        axs[0, i].imshow(longest_data[idx,18+i,:,:,0])\n",
    "        axs[0, i].set_title(f'Real frame {i+10}')\n",
    "\n",
    "    fig, axs = plt.subplots(2,9,figsize=(16,9))\n",
    "    for i in range(9):\n",
    "        axs[1, i].imshow(input_sequence[idx,9*3+i,:,:,0])\n",
    "        axs[1, i].set_title(f'Pred. frame {i+19}')\n",
    "        axs[0, i].imshow(longest_data[idx,9*3+i,:,:,0])\n",
    "        axs[0, i].set_title(f'Real frame {i+19}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
